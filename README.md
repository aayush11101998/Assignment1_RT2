# Assignment1_RT2

### Master:
Contains the sphynx documentation. Click **[here](https://aayush11101998.github.io/Assignment1_RT2/py-modindex.html)** to view the documentation
### Jupyter_notebook: 
Contains the Jupyter_notebook 
### SA : 
Contains statistical analysis Click **[here](https://github.com/aayush11101998/Assignment1_RT2/tree/statistical_analysis/statistical_data)** to see the statistical_data collected along with the images

This is the Jupyter_branch

## Jupyter_Notebook
In the jupyter notebook a user interface has been provided for the assignment-3 from research track-1. 
Data visualisation for the user to understand whats going on in a better way is also presented, which provides some insights about the number of times goal 
reached by a robot, an odometery followed and a laserscan plot. 
### Scope of improvement:
There is a scope of improvement with the jupyter user interface which is as follows:
1.) In the movebase package a new_goal button can be added which allows the user to select a new_goal. This is possible even now but the user has to wait unitl the robot reaches the current goal and then comes back to the position 0,0. 
2.) The user has to always scroll up and down to utilize the modalities first he/she has to select the button from modality selction and once it is done he/she again has to scroll down for navigating robot according to the chosen modLITY.
3.) The user has to wait initially because the robot will travel to coordinates (0.0, 0.0) and then only it will accept the chosen modilities. 
